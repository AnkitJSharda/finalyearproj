Codeforces [1] is one of many competitive programming
platforms that provide an opportunity to gain insights into
coding techniques. In a contest, participants solve about 5 to
10 well-defined algorithmic programming problems by writing
short stand-alone solutions in a programming language such
as C++, Java, or Python. Each solution is generally written by
only one person (user). It is known whether the solution passed
or failed. In addition, the user’s skill level (rating/rank) and
declared country are known. Most problems on Codeforces
have hundreds or thousands of passing submissions. Unlike
many other platforms, all submissions on Codeforces are
publicly viewable, making it an ideal candidate for analysis.
On Codeforces, users are assigned a numerical rating based
on their performance in past contests. Users are then assigned
one of ten ranks based on their rating, ranging from Newbie
to Legendary Grandmaster. These ranks are shown in the Data
Set section in Table II.
The goal of this project is to predict a user’s rank (within
one rank) and country based solely on a single passing source
code submission. As well, some interpretation of the learned
models is done to find differences in coding styles between
skill levels and countries. Since only passing submissions are
considered, predictions are based only on coding style and not
whether the code works or not (all code works).
Analysis from this project will not only highlight the coding
techniques of competitive programmers, but may also be
relevant for code written in industry or academia. While code
written in programming contests differs from real-world code,
some coding best practices may apply to both, and the analysis
techniques used here may also be applicable to other code
bases. Code from programming contests, however, is easier to
analyze than most code for the reasons described above(eg
written by exactly one person).
